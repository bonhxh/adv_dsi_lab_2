{"cells":[{"cell_type":"markdown","metadata":{"id":"uQ6wc2HE0pke"},"source":["# **Lab: Time-Series**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tQgxLRrvjiJb"},"source":["## Exercise 1: Feature Engineering\n","\n","In this exercise, we will work on time-series dataset containing observations related to bike sharing services:\n","https://code.datasciencedojo.com/datasciencedojo/datasets/tree/master/Bike%20Sharing\n","\n","The objective is to train a model that can accurately predict the volume bikes shared.\n","\n","The steps are:\n","1.   Setup Repository\n","2.   Load and Explore Dataset\n","3.   Prepare Data\n","4.   Split Dataset\n","5.   Baseline Model\n","6.   Push Changes\n"]},{"cell_type":"markdown","metadata":{"id":"smh_LhVjIg9s"},"source":["### 1. Setup Repository"]},{"cell_type":"markdown","metadata":{"id":"_fTLEcebNjhz"},"source":["**[1.1]** Go to a folder of your choice on your computer (where you store projects)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pe-loIVTNjqW"},"outputs":[],"source":["Go to a folder of your choice on your computer (where you store projects)-use anaconda prompt\n","# Placeholder for student's code (1 command line)\n","# Task:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4dL8A5y-NjtY"},"outputs":[],"source":["#Solution:\n","cd ~/Projects/adv_dsi"]},{"cell_type":"markdown","metadata":{"id":"vXcCZQOIgVIg"},"source":["[1.2] Create folder called `src`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LC1oBeMfgVPi"},"outputs":[],"source":["mkdir scr #skip this step"]},{"cell_type":"markdown","metadata":{"id":"EHQBJUHEQqcs"},"source":["**[1.2]** Copy the cookiecutter data science template"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bM-1oZYxQqmO"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Copy the cookiecutter data science template"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TbseMHf7Qqo2"},"outputs":[],"source":["#Solution:\n","cookiecutter -c v1 https://github.com/drivendata/cookiecutter-data-science  #write on cmd or anaconda prompt. ypu my need to go for pip install cookiecutter or conda config --add channels conda-forge,conda install cookiecutter(for anaconda)"]},{"cell_type":"markdown","metadata":{"id":"scwewLhrRB_y"},"source":["Follow the prompt (name the project and repo adv_dsi_lab_2)"]},{"cell_type":"markdown","metadata":{"id":"elPnd9JPQwkD"},"source":["**[1.3]** Go inside the created folder `adv_dsi_lab_2`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VlHqFVqQwuC"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Go inside the created folder adv_dsi_lab_2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"df9ydWQNQww0"},"outputs":[],"source":["#Solution:\n","cd adv_dsi_lab_2 #via git bash"]},{"cell_type":"markdown","metadata":{"id":"4MCoAnnacjS1"},"source":["**[1.4]** Initialise the repo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P-TPhgLMcjaL"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Initialise the repo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jTTOWPgjckKe"},"outputs":[],"source":["#Solution:\n","git init"]},{"cell_type":"markdown","metadata":{"id":"hGw8ot1UdHqg"},"source":["**[1.5]** Login into Github with your account (https://github.com/) and create a public repo with the name `adv_dsi_lab_2`"]},{"cell_type":"markdown","metadata":{"id":"jD4H0EtCdDFr"},"source":["**[1.6]** In your local repo `adv_dsi_lab_2`, link it with Github (replace the url with your username)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3fCS9HtdDNw"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Link repo with Github"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpxHoo3SdDQo"},"outputs":[],"source":["#Solution:\n","#e.g. git remote add origin https://github.com/AUbaid/adv_dsi_lab_2.git\n","git remote add origin https://github.com/bonhxh/adv_dsi_lab_2.git # [if you get error, run command git remote remove origin and try again.should solve the problemgit]"]},{"cell_type":"markdown","metadata":{"id":"Q25knaDhSirD"},"source":["**[1.7]** Add you changes to git staging area and commit them"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoA1ZL_dSi1r"},"outputs":[],"source":["# Placeholder for student's code (2 command lines)\n","# Task: Add you changes to git staging area and commit them"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qWbIKbjSi4_"},"outputs":[],"source":["#Solution:\n","git add .\n","git commit -m \"init\""]},{"cell_type":"markdown","metadata":{"id":"3oRUjdX0dbBu"},"source":["**[1.8]** Push your master branch to origin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UzrKvGtdbGy"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Push your master branch to origin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wv0pkcLkdbPL"},"outputs":[],"source":["#Solution:\n","git branch -M main\n","git push --set-upstream origin main #(main or master ) # git clone https://github.com/AUbaid/adsi-lab2-e1.git\n"]},{"cell_type":"markdown","metadata":{"id":"jxQRDLu2C6D4"},"source":["**[1.9]** Create a new git branch called `data_prep`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y-S-ZdcqdoF7"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Create a new git branch called data_prep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zBD6K4MXC6rA"},"outputs":[],"source":["#Solution:\n","git checkout -b data_prep"]},{"cell_type":"markdown","metadata":{"id":"l9AnbpOpckUl"},"source":["**[1.10]** Download the dataset into the folder data/raw"]},{"cell_type":"markdown","metadata":{"id":"yTjwF_joDWnE"},"source":["**[1.11]** Navigate the folder `notebooks` and create a new jupyter notebook called `1_data_prep.ipynb`"]},{"cell_type":"markdown","metadata":{"id":"_NCwQQFkU3v5"},"source":["### 2.   Load and Explore Dataset"]},{"cell_type":"markdown","metadata":{"id":"4JI0kZJxpkoK"},"source":["**[2.1]** Import the pandas and numpy package"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85PHb6M7p57j"},"outputs":[],"source":["# Placeholder for student's code (2 lines of Python code)\n","# Task: Import the pandas and numpy package"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"1sXpjWA8pz0q"},"outputs":[],"source":["# Solution\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"R-Zy6Oq8pkuB"},"source":["**[2.2]** Load the dataset into dataframe called df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZresJIasqpgH"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Load the dataset into dataframe called df"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Q1iETWjDftMg"},"outputs":[],"source":["#Solution:\n","df = pd.read_csv('../data/raw/day.csv')"]},{"cell_type":"markdown","metadata":{"id":"CLyMcoNCsx2k"},"source":["**[2.3]** Display the first 5 rows of df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CJKSOaRPsbuD"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Display the first 5 rows of df"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xvnbhiPhs0ZP"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>dteday</th>\n","      <th>season</th>\n","      <th>yr</th>\n","      <th>mnth</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weathersit</th>\n","      <th>temp</th>\n","      <th>atemp</th>\n","      <th>hum</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>registered</th>\n","      <th>cnt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2011-01-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.344167</td>\n","      <td>0.363625</td>\n","      <td>0.805833</td>\n","      <td>0.160446</td>\n","      <td>331</td>\n","      <td>654</td>\n","      <td>985</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>2011-01-02</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.363478</td>\n","      <td>0.353739</td>\n","      <td>0.696087</td>\n","      <td>0.248539</td>\n","      <td>131</td>\n","      <td>670</td>\n","      <td>801</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>2011-01-03</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.196364</td>\n","      <td>0.189405</td>\n","      <td>0.437273</td>\n","      <td>0.248309</td>\n","      <td>120</td>\n","      <td>1229</td>\n","      <td>1349</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>2011-01-04</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.200000</td>\n","      <td>0.212122</td>\n","      <td>0.590435</td>\n","      <td>0.160296</td>\n","      <td>108</td>\n","      <td>1454</td>\n","      <td>1562</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>2011-01-05</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.226957</td>\n","      <td>0.229270</td>\n","      <td>0.436957</td>\n","      <td>0.186900</td>\n","      <td>82</td>\n","      <td>1518</td>\n","      <td>1600</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n","0        1  2011-01-01       1   0     1        0        6           0   \n","1        2  2011-01-02       1   0     1        0        0           0   \n","2        3  2011-01-03       1   0     1        0        1           1   \n","3        4  2011-01-04       1   0     1        0        2           1   \n","4        5  2011-01-05       1   0     1        0        3           1   \n","\n","   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n","0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n","1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n","2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n","3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n","4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n","\n","    cnt  \n","0   985  \n","1   801  \n","2  1349  \n","3  1562  \n","4  1600  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Solution\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"gQgeYjQDs12m"},"source":["**[2.4]** Display the dimensions (shape) of df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dOA7T87hs19l"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Task: Display the dimensions (shape) of df"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Dg_89DlAs1_w"},"outputs":[{"data":{"text/plain":["(731, 16)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Solution\n","df.shape"]},{"cell_type":"markdown","metadata":{"id":"xyle1PCws7B0"},"source":["**[2.5]** Display the summary (info) of df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RrNAGFzxs7JU"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Display the summary (info) of df"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"l1msvlh7s7Lt"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 731 entries, 0 to 730\n","Data columns (total 16 columns):\n"," #   Column      Non-Null Count  Dtype  \n","---  ------      --------------  -----  \n"," 0   instant     731 non-null    int64  \n"," 1   dteday      731 non-null    object \n"," 2   season      731 non-null    int64  \n"," 3   yr          731 non-null    int64  \n"," 4   mnth        731 non-null    int64  \n"," 5   holiday     731 non-null    int64  \n"," 6   weekday     731 non-null    int64  \n"," 7   workingday  731 non-null    int64  \n"," 8   weathersit  731 non-null    int64  \n"," 9   temp        731 non-null    float64\n"," 10  atemp       731 non-null    float64\n"," 11  hum         731 non-null    float64\n"," 12  windspeed   731 non-null    float64\n"," 13  casual      731 non-null    int64  \n"," 14  registered  731 non-null    int64  \n"," 15  cnt         731 non-null    int64  \n","dtypes: float64(4), int64(11), object(1)\n","memory usage: 91.5+ KB\n"]}],"source":["# Solution\n","df.info()"]},{"cell_type":"markdown","metadata":{"id":"eWLgqm2YtAgP"},"source":["**[2.6]** Display the descriptive statistics of df\n"]},{"cell_type":"markdown","metadata":{"id":"PZmnqzgLemuH"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ZnOCCtjtAnj"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Display the descriptive statictics of df"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"FQLSaoXltAp-"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>season</th>\n","      <th>yr</th>\n","      <th>mnth</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weathersit</th>\n","      <th>temp</th>\n","      <th>atemp</th>\n","      <th>hum</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>registered</th>\n","      <th>cnt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","      <td>731.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>366.000000</td>\n","      <td>2.496580</td>\n","      <td>0.500684</td>\n","      <td>6.519836</td>\n","      <td>0.028728</td>\n","      <td>2.997264</td>\n","      <td>0.683995</td>\n","      <td>1.395349</td>\n","      <td>0.495385</td>\n","      <td>0.474354</td>\n","      <td>0.627894</td>\n","      <td>0.190486</td>\n","      <td>848.176471</td>\n","      <td>3656.172367</td>\n","      <td>4504.348837</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>211.165812</td>\n","      <td>1.110807</td>\n","      <td>0.500342</td>\n","      <td>3.451913</td>\n","      <td>0.167155</td>\n","      <td>2.004787</td>\n","      <td>0.465233</td>\n","      <td>0.544894</td>\n","      <td>0.183051</td>\n","      <td>0.162961</td>\n","      <td>0.142429</td>\n","      <td>0.077498</td>\n","      <td>686.622488</td>\n","      <td>1560.256377</td>\n","      <td>1937.211452</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.059130</td>\n","      <td>0.079070</td>\n","      <td>0.000000</td>\n","      <td>0.022392</td>\n","      <td>2.000000</td>\n","      <td>20.000000</td>\n","      <td>22.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>183.500000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.337083</td>\n","      <td>0.337842</td>\n","      <td>0.520000</td>\n","      <td>0.134950</td>\n","      <td>315.500000</td>\n","      <td>2497.000000</td>\n","      <td>3152.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>366.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>7.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.498333</td>\n","      <td>0.486733</td>\n","      <td>0.626667</td>\n","      <td>0.180975</td>\n","      <td>713.000000</td>\n","      <td>3662.000000</td>\n","      <td>4548.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>548.500000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>10.000000</td>\n","      <td>0.000000</td>\n","      <td>5.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>0.655417</td>\n","      <td>0.608602</td>\n","      <td>0.730209</td>\n","      <td>0.233214</td>\n","      <td>1096.000000</td>\n","      <td>4776.500000</td>\n","      <td>5956.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>731.000000</td>\n","      <td>4.000000</td>\n","      <td>1.000000</td>\n","      <td>12.000000</td>\n","      <td>1.000000</td>\n","      <td>6.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>0.861667</td>\n","      <td>0.840896</td>\n","      <td>0.972500</td>\n","      <td>0.507463</td>\n","      <td>3410.000000</td>\n","      <td>6946.000000</td>\n","      <td>8714.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          instant      season          yr        mnth     holiday     weekday  \\\n","count  731.000000  731.000000  731.000000  731.000000  731.000000  731.000000   \n","mean   366.000000    2.496580    0.500684    6.519836    0.028728    2.997264   \n","std    211.165812    1.110807    0.500342    3.451913    0.167155    2.004787   \n","min      1.000000    1.000000    0.000000    1.000000    0.000000    0.000000   \n","25%    183.500000    2.000000    0.000000    4.000000    0.000000    1.000000   \n","50%    366.000000    3.000000    1.000000    7.000000    0.000000    3.000000   \n","75%    548.500000    3.000000    1.000000   10.000000    0.000000    5.000000   \n","max    731.000000    4.000000    1.000000   12.000000    1.000000    6.000000   \n","\n","       workingday  weathersit        temp       atemp         hum   windspeed  \\\n","count  731.000000  731.000000  731.000000  731.000000  731.000000  731.000000   \n","mean     0.683995    1.395349    0.495385    0.474354    0.627894    0.190486   \n","std      0.465233    0.544894    0.183051    0.162961    0.142429    0.077498   \n","min      0.000000    1.000000    0.059130    0.079070    0.000000    0.022392   \n","25%      0.000000    1.000000    0.337083    0.337842    0.520000    0.134950   \n","50%      1.000000    1.000000    0.498333    0.486733    0.626667    0.180975   \n","75%      1.000000    2.000000    0.655417    0.608602    0.730209    0.233214   \n","max      1.000000    3.000000    0.861667    0.840896    0.972500    0.507463   \n","\n","            casual   registered          cnt  \n","count   731.000000   731.000000   731.000000  \n","mean    848.176471  3656.172367  4504.348837  \n","std     686.622488  1560.256377  1937.211452  \n","min       2.000000    20.000000    22.000000  \n","25%     315.500000  2497.000000  3152.000000  \n","50%     713.000000  3662.000000  4548.000000  \n","75%    1096.000000  4776.500000  5956.000000  \n","max    3410.000000  6946.000000  8714.000000  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Solution\n","df.describe()"]},{"cell_type":"markdown","metadata":{"id":"miQ6SiKlscLx"},"source":["### 3. Prepare Data"]},{"cell_type":"markdown","metadata":{"id":"NtuF1V6ctwn-"},"source":["**[3.1]** Create a copy of df and save it into a variable called df_cleaned"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zqaz1C7DtwuU"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Create a copy of df and save it into a variable called df_cleaned"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"HrXR7NCLtwxB"},"outputs":[],"source":["# Solution\n","df_cleaned = df.copy()"]},{"cell_type":"markdown","metadata":{"id":"e9_f6hfquKRF"},"source":["**[3.2]** Remove the column `instant` from the dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAcH_Jb6uKXz"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Remove the column instant from the dataframe"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"SscAg2GrQQlm"},"outputs":[],"source":["# Solution\n","df_cleaned.drop('instant', axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDZ68EVnSrHS"},"outputs":[],"source":["# Placeholder for student's code (multiple lines of Python code)\n","# Task: Build a function to convert into datetime"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"OBZy7jqMQa8Z"},"outputs":[],"source":["# Solution\n","def convert_to_date(df, cols:list):\n","    \"\"\"Convert specified columns from a Pandas dataframe into datetime\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        Input dataframe\n","    cols : list\n","        List of columns to be converted\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        Pandas dataframe with converted columns\n","    \"\"\"\n","    import pandas as pd\n","\n","    for col in cols:\n","        if col in df.columns:\n","            df[col] = pd.to_datetime(df[col])\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"yvEl7w7GTWfL"},"source":["**[3.3]** Convert the column `dteday` with your function `convert_to_date`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNU9-pDNTWnA"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Convert the column dteday with your function convert_to_date"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Xuo9WuYhTWr4"},"outputs":[],"source":["# Solution\n","df_cleaned = convert_to_date(df_cleaned, ['dteday'])"]},{"cell_type":"markdown","metadata":{"id":"w2v1vLMWTofp"},"source":["**[3.4]** Extract the year component from `dteday` and save the results in the column `yr`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BcTo7drqTom4"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Extract the year component from dteday and save the results in the column yr"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"dfUpbRYSTopS"},"outputs":[],"source":["# Solution\n","df_cleaned['yr'] = df_cleaned['dteday'].dt.year"]},{"cell_type":"markdown","metadata":{"id":"lt8YYcHuTsDs"},"source":["**[3.5]** Extract the month name component from `dteday` and save the results in the column `mnth`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Fs5Lt8jTsLK"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Extract the month name component from dteday and save the results in the column mnth"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"z6isEtGBTsNz"},"outputs":[],"source":["# Solution\n","df_cleaned['mnth'] = df_cleaned['dteday'].dt.month_name()"]},{"cell_type":"markdown","metadata":{"id":"ruXvMIbwTt8E"},"source":["**[3.6]** Extract the day of week component from `dteday` and save the results in the column `weekday`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fz6_BQaLTuEC"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Extract the day of week component from dteday and save the results in the column weekday"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"kDpsPAW0TuGg"},"outputs":[],"source":["# Solution\n","df_cleaned['weekday'] = df_cleaned['dteday'].dt.day_name()"]},{"cell_type":"markdown","metadata":{"id":"RWVnvt9ZUV2N"},"source":["**[3.7]** Create a dictionary called `season_mapping` with the following key-value pairs:\n","- 1: 'winter',\n","- 2: 'spring',\n","- 3: 'summer',\n","- 4: 'autumn',\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mL7aSurmUWFr"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Create a dictionary called season_mapping"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Xf2fH-0qUWNt"},"outputs":[],"source":["# Solution\n","season_mapping = {\n","    1: 'winter',\n","    2: 'spring',\n","    3: 'summer',\n","    4: 'autumn',\n","}"]},{"cell_type":"markdown","metadata":{"id":"WbqV7K55U1ER"},"source":["**[3.8]** Remap the values of `season` to the one specified in `season_mapping`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DwNLDCNUU1MF"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Remap the values of season to the one specified in season_mapping"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ZXZ-V4PZU1OV"},"outputs":[],"source":["# Solution\n","df_cleaned['season'] = df_cleaned['season'].map(season_mapping)"]},{"cell_type":"markdown","metadata":{"id":"gWVXbfBNUxo4"},"source":["**[3.9]** Create a dictionary called `weather_mapping` with the following key-value pairs:\n","- 1: 'clear',\n","- 2: 'cloudy',\n","- 3: 'rain',\n","- 4: 'heavy'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kd9YwpZUxwZ"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Create a dictionary called weather_mapping"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"dlmfBvKhUxy5"},"outputs":[],"source":["# Solution\n","weather_mapping = {\n","    1: 'clear',\n","    2: 'cloudy',\n","    3: 'rain',\n","    4: 'heavy'\n","}"]},{"cell_type":"markdown","metadata":{"id":"wWtIeSqxVFig"},"source":["**[3.10]** Remap the values of `weathersit` to the one specified in `weather_mapping`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5yOXjoPhVFqv"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Remap the values of weathersit to the one specified in weather_mapping"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"j-g7poxaVFts"},"outputs":[],"source":["# Solution\n","df_cleaned['weathersit'] = df_cleaned['weathersit'].map(weather_mapping)"]},{"cell_type":"markdown","metadata":{"id":"Ekt7tuoFVhYO"},"source":["**[3.11]** Change the value of `holiday` to `1` for the observation where `dteday` is `2011-01-01`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xOezaBTXVhgQ"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Change the value of holiday to 1 for the observation where dteday is 2011-01-01"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"lS3iJe9rVhiq"},"outputs":[],"source":["# Solution\n","df_cleaned.loc[df_cleaned['dteday'] == '2011-01-01', 'holiday'] = 1"]},{"cell_type":"markdown","metadata":{"id":"tlL5JD39ViV1"},"source":["**[3.12]** Create a new column called `holiday_date` with only missing values and convert this column to datetime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKsjg6JwVicE"},"outputs":[],"source":["# Placeholder for student's code (2 lines of Python code)\n","# Task: Create a new column called `holiday_date` with only missing values and convert this column to datetime"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-Jg3oodwVieK"},"outputs":[],"source":["# Solution\n","df_cleaned['holidaydate'] = np.nan\n","df_cleaned = convert_to_date(df_cleaned, ['holidaydate'])"]},{"cell_type":"markdown","metadata":{"id":"X7wmbxnNWA7e"},"source":["**[3.13]** Create a binary variable called `holiday_mask` that will state which observations have the value `1` in column `holiday`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"COsF1eAiWBDF"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Create a binary variable called holiday_mask that will state which observations have the value 1 in column holiday"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"z95JSCyhWBFT"},"outputs":[],"source":["# Solution\n","holiday_mask = df_cleaned['holiday'] == 1"]},{"cell_type":"markdown","metadata":{"id":"Kf-78qTOWyi5"},"source":["**[3.14]** Change the values of `holidaydate` to be equals to `dteday` for all the observations that have the value 1 in column holiday (use `holiday_mask`)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sV3uiNUXWyqn"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Change the values of holidaydate to be equals to dteday for all the observations that have the value 1 in column holiday (use holiday_mask)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"0JeFvx7WWys9"},"outputs":[],"source":["# Solution\n","df_cleaned.loc[holiday_mask, 'holidaydate'] = df_cleaned.loc[holiday_mask, 'dteday']"]},{"cell_type":"markdown","metadata":{"id":"fJAkm9SrXVlv"},"source":["**[3.15]** Create a new column called `last_holiday` that will be equals to `holidaydate` but with forward filling for missing values (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYVdm7fYXVtM"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Create a new column called last_holiday that will be equals to holidaydate but with forward filling for missing values"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"GqtMCxNEXVvi"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/w7/cvmrvdgx00j4q4qkhbr15cb80000gn/T/ipykernel_85029/3059644967.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df_cleaned['last_holiday'] = df_cleaned['holidaydate'].fillna(method='ffill')\n"]}],"source":["# Solution\n","df_cleaned['last_holiday'] = df_cleaned['holidaydate'].fillna(method='ffill')"]},{"cell_type":"markdown","metadata":{"id":"USzqfk4KXZMg"},"source":["**[3.16]** Create a new column called `last_holiday` that will be equals to `holidaydate` but with back filling for missing values (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pYn8kQdXZTj"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Create a new column called last_holiday that will be equals to holidaydate but with back filling for missing values"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"LsAspiLZXZVh"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/w7/cvmrvdgx00j4q4qkhbr15cb80000gn/T/ipykernel_85029/1745752607.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df_cleaned['next_holiday'] = df_cleaned['holidaydate'].fillna(method='bfill')\n"]}],"source":["# Solution\n","df_cleaned['next_holiday'] = df_cleaned['holidaydate'].fillna(method='bfill')"]},{"cell_type":"markdown","metadata":{"id":"3x41TF2uX9xL"},"source":["**[3.17]** Replace missing values for `next_holiday` with the timestamp '2013-01-01`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RscpgMlWX96b"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task:"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"jBM4dGGnX-Bq"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/w7/cvmrvdgx00j4q4qkhbr15cb80000gn/T/ipykernel_85029/919995417.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df_cleaned['next_holiday'].fillna(pd.Timestamp('2013-01-01'), inplace=True)\n"]}],"source":["# Solution\n","df_cleaned['next_holiday'].fillna(pd.Timestamp('2013-01-01'), inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"PwIf-SWsYCpQ"},"source":["**[3.18]** Calculate the number of days for each observation between the current date and last holiday date. Save the results in a new column called `days_last_holiday`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_PwJp4GJYCwv"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Calculate the number of days for each observation between the current date and last holiday date. Save the results in a new column called days_last_holiday"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"6V181_DAYCzK"},"outputs":[],"source":["# Solution\n","df_cleaned['days_last_holiday'] = (df_cleaned['dteday'] - df_cleaned['last_holiday']).dt.days"]},{"cell_type":"markdown","metadata":{"id":"rq1EabXPYEih"},"source":["**[3.19]** Calculate the number of days for each observation between the current date and next holiday date. Save the results in a new column called `days_next_holiday`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvm1SpzCYEpI"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Calculate the number of days for each observation between the current date and next holiday date. Save the results in a new column called days_next_holiday"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"D0TUCzTaYErV"},"outputs":[],"source":["# Solution\n","df_cleaned['days_next_holiday'] = (df_cleaned['next_holiday'] - df_cleaned['dteday']).dt.days"]},{"cell_type":"markdown","metadata":{"id":"Kz1v7Tq-YxK4"},"source":["**[3.20]** Create a variable called `cat_cols` that contains the names of the categorical columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7UYg8U5fYxR1"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Create a variable called cat_cols that contains the names of the categorical columns"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"66Lhdy5ZYxUK"},"outputs":[],"source":["# Solution\n","cat_cols = ['season','mnth','holiday','weekday','workingday','weathersit']"]},{"cell_type":"markdown","metadata":{"id":"qFGEj92zZKUX"},"source":["**[3.21]** Perform One-Hot encoding on the categorical features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hiwxa2PLZKb6"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Perform One-Hot encoding on the categorical features"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"HMSXXBBOZKfP"},"outputs":[],"source":["# Solution\n","df_cleaned = pd.get_dummies(df_cleaned, columns=cat_cols)"]},{"cell_type":"markdown","metadata":{"id":"7gZaG_dX1Pr8"},"source":["**[3.22]** Save the dataframe in the `/data/interim` folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpOB_KFN1Pyi"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Save the dataframe in the /data/interim folder"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"v4b8t5ur1P50"},"outputs":[],"source":["# Solution\n","df_cleaned.to_csv('../data/interim/day.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"DfBjg3tHYwn7"},"source":["**[3.23]** Remove the following columns: 'dteday', 'holidaydate', 'last_holiday', 'next_holiday'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lRQb9GqyYwvq"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Remove the following columns: 'dteday', 'holidaydate', 'last_holiday', 'next_holiday'"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"SaiZCh_LYwyL"},"outputs":[],"source":["# Solution\n","df_cleaned.drop(['dteday', 'holidaydate', 'last_holiday', 'next_holiday'], axis=1, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"N8MNBrC4Zgz6"},"source":["### 4. Split Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00BWv65bZg7C"},"outputs":[],"source":["# Placeholder for student's code (multiple lines of Python code)\n","# Task: Create a subset function"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"Eejq-COGZhCP"},"outputs":[],"source":["# Solution\n","def subset_x_y(target, features, start_index:int, end_index:int):\n","    \"\"\"Keep only the rows for X and y sets from the specified indexes\n","\n","    Parameters\n","    ----------\n","    target : pd.DataFrame\n","        Dataframe containing the target\n","    features : pd.DataFrame\n","        Dataframe containing all features\n","    features : int\n","        Index of the starting observation\n","    features : int\n","        Index of the ending observation\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        Subsetted Pandas dataframe containing the target\n","    pd.DataFrame\n","        Subsetted Pandas dataframe containing all features\n","    \"\"\"\n","\n","    return features[start_index:end_index], target[start_index:end_index]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yb11FmKJbcTP"},"outputs":[],"source":["# Placeholder for student's code (multiple lines of Python code)\n","# Task: Create a function to split data by time"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"BTvTQeHLbcWj"},"outputs":[],"source":["# Solution\n","def split_sets_by_time(df, target_col, test_ratio=0.2):\n","    \"\"\"Split sets by indexes for an ordered dataframe\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        Input dataframe\n","    target_col : str\n","        Name of the target column\n","    test_ratio : float\n","        Ratio used for the validation and testing sets (default: 0.2)\n","\n","    Returns\n","    -------\n","    Numpy Array\n","        Features for the training set\n","    Numpy Array\n","        Target for the training set\n","    Numpy Array\n","        Features for the validation set\n","    Numpy Array\n","        Target for the validation set\n","    Numpy Array\n","        Features for the testing set\n","    Numpy Array\n","        Target for the testing set\n","    \"\"\"\n","\n","    df_copy = df.copy()\n","    target = df_copy.pop(target_col)\n","    cutoff = int(len(target) / 5)\n","\n","    X_train, y_train = subset_x_y(target=target, features=df_copy, start_index=0, end_index=-cutoff*2)\n","    X_val, y_val     = subset_x_y(target=target, features=df_copy, start_index=-cutoff*2, end_index=-cutoff)\n","    X_test, y_test   = subset_x_y(target=target, features=df_copy, start_index=-cutoff, end_index=len(target))\n","\n","    return X_train, y_train, X_val, y_val, X_test, y_test"]},{"cell_type":"markdown","metadata":{"id":"sJNZfvA4dJ9X"},"source":["**[4.1]** Import your new function `split_sets_by_time` and split the data into several sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rdui0TivdKGE"},"outputs":[],"source":["# Placeholder for student's code (2 lines of Python code)\n","# Task: Import your new function split_sets_by_time and split the data into several sets"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"fev4FWAYdU1G"},"outputs":[],"source":["# Solution\n","\n","\n","X_train, y_train, X_val, y_val, X_test, y_test = split_sets_by_time(df_cleaned, 'cnt', test_ratio=0.2)"]},{"cell_type":"markdown","metadata":{"id":"xpaobmrXdt2C"},"source":["**[4.2]** Define a function called `save_sets` with the following logics:\n","- input parameters: features and target for training, validation and testing sets and path to folder (`path`)\n","- logics: save the different sets locally with numpy if they exist\n","- output parameters: None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIJme1Z2dt9P"},"outputs":[],"source":["# Placeholder for student's code (multiple lines of Python code)\n","# Task: Create a function to save sets"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"o5N89bfqdt_g"},"outputs":[],"source":["# Solution\n","\n","def save_sets(X_train=None, y_train=None, X_val=None, y_val=None, X_test=None, y_test=None, path='../data/processed/'):\n","    \"\"\"Save the different sets locally\n","\n","    Parameters\n","    ----------\n","    X_train: Numpy Array\n","        Features for the training set\n","    y_train: Numpy Array\n","        Target for the training set\n","    X_val: Numpy Array\n","        Features for the validation set\n","    y_val: Numpy Array\n","        Target for the validation set\n","    X_test: Numpy Array\n","        Features for the testing set\n","    y_test: Numpy Array\n","        Target for the testing set\n","    path : str\n","        Path to the folder where the sets will be saved (default: '../data/processed/')\n","\n","    Returns\n","    -------\n","    \"\"\"\n","    import numpy as np\n","\n","    if X_train is not None:\n","      np.save(f'{path}X_train', X_train)\n","    if X_val is not None:\n","      np.save(f'{path}X_val',   X_val)\n","    if X_test is not None:\n","      np.save(f'{path}X_test',  X_test)\n","    if y_train is not None:\n","      np.save(f'{path}y_train', y_train)\n","    if y_val is not None:\n","      np.save(f'{path}y_val',   y_val)\n","    if y_test is not None:\n","      np.save(f'{path}y_test',  y_test)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHSzxM1HdyMQ"},"outputs":[],"source":["# Placeholder for student's code (multiple lines of Python code)\n","# Task: Create a function to load sets"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"T1Ln9hzNdySK"},"outputs":[],"source":["# Solution\n","\n","def load_sets(path='../data/processed/', val=False):\n","    \"\"\"Load the different locally save sets\n","\n","    Parameters\n","    ----------\n","    path : str\n","        Path to the folder where the sets are saved (default: '../data/processed/')\n","\n","    Returns\n","    -------\n","    Numpy Array\n","        Features for the training set\n","    Numpy Array\n","        Target for the training set\n","    Numpy Array\n","        Features for the validation set\n","    Numpy Array\n","        Target for the validation set\n","    Numpy Array\n","        Features for the testing set\n","    Numpy Array\n","        Target for the testing set\n","    \"\"\"\n","    import numpy as np\n","    import os.path\n","\n","    X_train = np.load(f'{path}X_train.npy') if os.path.isfile(f'{path}X_train.npy') else None\n","    X_val   = np.load(f'{path}X_val.npy'  ) if os.path.isfile(f'{path}X_val.npy')   else None\n","    X_test  = np.load(f'{path}X_test.npy' ) if os.path.isfile(f'{path}X_test.npy')  else None\n","    y_train = np.load(f'{path}y_train.npy') if os.path.isfile(f'{path}y_train.npy') else None\n","    y_val   = np.load(f'{path}y_val.npy'  ) if os.path.isfile(f'{path}y_val.npy')   else None\n","    y_test  = np.load(f'{path}y_test.npy' ) if os.path.isfile(f'{path}y_test.npy')  else None\n","\n","    return X_train, y_train, X_val, y_val, X_test, y_test"]},{"cell_type":"markdown","metadata":{"id":"4z3CpwGbd4Fi"},"source":["**[4.3]** Import your new function and save the sets into the folder `data/processed`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aNuLNsVyd4M2"},"outputs":[],"source":["# Placeholder for student's code (multiple lines of Python code)\n","# Task: Import your new function and save the sets into the folder data/processed"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"Mpr1RQkLd4PS"},"outputs":[],"source":["# Solution\n","\n","\n","save_sets(X_train, y_train, X_val, y_val, X_test, y_test, path='../data/processed/')"]},{"cell_type":"markdown","metadata":{"id":"JUEbyrm2ZzhL"},"source":["### 5. Baseline Model"]},{"cell_type":"markdown","metadata":{"id":"faMubeDzZzuX"},"source":["**[5.1]** Calculate the average of the target variable for the training set and save it into a variable called `y_mean`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSrYPUCPZz1u"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Calculate the average of the target variable for the training set and save it into a variable called y_mean"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"vBSoR7LTZz3-"},"outputs":[],"source":["# Solution:\n","y_mean = y_train.mean()"]},{"cell_type":"markdown","metadata":{"id":"HKBNkwgmgVPQ"},"source":["**[5.2]** Create a numpy array called `y_base` of dimensions (len(y_train), 1) filled with this value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ohrllnggVWA"},"outputs":[],"source":["# Placeholder for student's code (1 line of Python code)\n","# Task: Create a numpy array called y_base of dimensions (len(y_train), 1) filled with this value"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"5lna_U35gVYR"},"outputs":[],"source":["# Solution:\n","y_base = np.full((len(y_train), 1), y_mean)"]},{"cell_type":"markdown","metadata":{"id":"ORcJNo4ygaRa"},"source":["**[5.3]** Define a function called `print_reg_perf` with the following logics:\n","- input parameters: predicted target (`y_preds`), actual target (`y_actuals`) and name of the set (`set_name`)\n","- logics: Print the RMSE and MAE for the provided data\n","- output parameters: None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgVyt-4egaXE"},"outputs":[],"source":["# Placeholder for student's code (multiple lines of Python code)\n","# Task: In src/models/ create a file called performance.py. Inside it you will define a function called print_reg_perf"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"QkXUqKMcgaZN"},"outputs":[],"source":["def print_reg_perf(y_preds, y_actuals, set_name=None):\n","    \"\"\"Print the RMSE and MAE for the provided data\n","\n","    Parameters\n","    ----------\n","    y_preds : Numpy Array\n","        Predicted target\n","    y_actuals : Numpy Array\n","        Actual target\n","    set_name : str\n","        Name of the set to be printed\n","\n","    Returns\n","    -------\n","    \"\"\"\n","    from sklearn.metrics import mean_squared_error as mse\n","    from sklearn.metrics import mean_absolute_error as mae\n","\n","    print(f\"RMSE {set_name}: {mse(y_actuals, y_preds, squared=False)}\")\n","    print(f\"MAE {set_name}: {mae(y_actuals, y_preds)}\")"]},{"cell_type":"markdown","metadata":{"id":"ekaUYYjqgfcF"},"source":["**[5.4]** Display the RMSE and MAE scores of this baseline model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSzb5ZsYgfhf"},"outputs":[],"source":["# Placeholder for student's code (2 lines of Python code)\n","# Task: Display the RMSE and MAE scores of this baseline model"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"rwqi0xR3gfjt"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE Training: 1324.7868420297616\n","MAE Training: 1132.7364532147508\n"]},{"name":"stderr","output_type":"stream","text":["/Users/bonheur/Documents/50 - WORK/70 - MYKB/00 - Trainings/Data Science ML/UTS/venv/lib/python3.9/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]}],"source":["print_reg_perf(y_preds=y_base, y_actuals=y_train, set_name='Training')"]},{"cell_type":"markdown","metadata":{"id":"1yX0Ocg4hcZM"},"source":["### 6.   Push changes"]},{"cell_type":"markdown","metadata":{"id":"3guOKU9gjrmp"},"source":["**[6.1]** Add you changes to git staging area"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lKuRNeqAj0ym"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Add you changes to git staging area"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axcj-jS0jruy"},"outputs":[],"source":["# Solution:\n","git add ."]},{"cell_type":"markdown","metadata":{"id":"6nUK2dp_j67X"},"source":["**[6.2]** Create the snapshot of your repository and add a description"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-M-aS-Ij7EE"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Create the snapshot of your repository and add a description"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zovhzXRxj7Il"},"outputs":[],"source":["# Solution:\n","git commit -m \"linear regression with poly 2\""]},{"cell_type":"markdown","metadata":{"id":"Y9FciIQZj7nX"},"source":["**[6.3]** Push your snapshot to Github"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IR7i6D5hj7uO"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Push your snapshot to Github"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WaVAgJ4Aj7wi"},"outputs":[],"source":["# Solution:\n","git push --set-upstream origin data_prep"]},{"cell_type":"markdown","metadata":{"id":"d7a6bwMniAs1"},"source":["**[6.4]** Check out to the master branch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eM9v_33XiA1I"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Check out to the master branch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6-AI0x7iA4M"},"outputs":[],"source":["# Solution:\n","git checkout main"]},{"cell_type":"markdown","metadata":{"id":"v98Ka9kNiBLw"},"source":["**[6.5]** Pull the latest updates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNZb1PyEjIOP"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Pull the latest updates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TJAEYxPjIRS"},"outputs":[],"source":["git pull"]},{"cell_type":"markdown","metadata":{"id":"mQo0puPbwpN5"},"source":["**[6.6]** Check out to the `data_prep` branch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyNnqElJwpVx"},"outputs":[],"source":["# Placeholder for student's code (1 command line)\n","# Task: Check out to the data_prep branch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"blENS_pdwpXs"},"outputs":[],"source":["# Solution:\n","git checkout data_prep"]},{"cell_type":"markdown","metadata":{"id":"pGd3Xdx-jJDk"},"source":["**[6.7]** Merge the `master` branch and push your changes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEYg8wauiBUb"},"outputs":[],"source":["# Placeholder for student's code (2 command lines)\n","# Task: Merge the master branch and push your changes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YNZunyVsiBXd"},"outputs":[],"source":["# Solution:\n","git checkout main\n","git merge data_prep\n","git push"]},{"cell_type":"markdown","metadata":{"id":"8B98cSvWkB-x"},"source":["**[6.8]** Go to Github and merge the branch after reviewing the code and fixing any conflict\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
